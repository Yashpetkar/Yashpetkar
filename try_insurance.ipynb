{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMUJi9WTrQJFT/truynR3Je",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Yashpetkar/Yashpetkar/blob/main/try_insurance.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the CSV file\n",
        "file_path = '/content/insurance_claims.csv'\n",
        "data = pd.read_csv(file_path)\n",
        "\n",
        "# Display the first few rows of the dataset\n",
        "data.head(), data.info()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AjigtgNcdOp6",
        "outputId": "9bd7d100-ef93-464d-f5b7-7bc1658a72ba"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1000 entries, 0 to 999\n",
            "Data columns (total 40 columns):\n",
            " #   Column                       Non-Null Count  Dtype  \n",
            "---  ------                       --------------  -----  \n",
            " 0   months_as_customer           1000 non-null   int64  \n",
            " 1   age                          1000 non-null   int64  \n",
            " 2   policy_number                1000 non-null   int64  \n",
            " 3   policy_bind_date             1000 non-null   object \n",
            " 4   policy_state                 1000 non-null   object \n",
            " 5   policy_csl                   1000 non-null   object \n",
            " 6   policy_deductable            1000 non-null   int64  \n",
            " 7   policy_annual_premium        1000 non-null   float64\n",
            " 8   umbrella_limit               1000 non-null   int64  \n",
            " 9   insured_zip                  1000 non-null   int64  \n",
            " 10  insured_sex                  1000 non-null   object \n",
            " 11  insured_education_level      1000 non-null   object \n",
            " 12  insured_occupation           1000 non-null   object \n",
            " 13  insured_hobbies              1000 non-null   object \n",
            " 14  insured_relationship         1000 non-null   object \n",
            " 15  capital-gains                1000 non-null   int64  \n",
            " 16  capital-loss                 1000 non-null   int64  \n",
            " 17  incident_date                1000 non-null   object \n",
            " 18  incident_type                1000 non-null   object \n",
            " 19  collision_type               1000 non-null   object \n",
            " 20  incident_severity            1000 non-null   object \n",
            " 21  authorities_contacted        909 non-null    object \n",
            " 22  incident_state               1000 non-null   object \n",
            " 23  incident_city                1000 non-null   object \n",
            " 24  incident_location            1000 non-null   object \n",
            " 25  incident_hour_of_the_day     1000 non-null   int64  \n",
            " 26  number_of_vehicles_involved  1000 non-null   int64  \n",
            " 27  property_damage              1000 non-null   object \n",
            " 28  bodily_injuries              1000 non-null   int64  \n",
            " 29  witnesses                    1000 non-null   int64  \n",
            " 30  police_report_available      1000 non-null   object \n",
            " 31  total_claim_amount           1000 non-null   int64  \n",
            " 32  injury_claim                 1000 non-null   int64  \n",
            " 33  property_claim               1000 non-null   int64  \n",
            " 34  vehicle_claim                1000 non-null   int64  \n",
            " 35  auto_make                    1000 non-null   object \n",
            " 36  auto_model                   1000 non-null   object \n",
            " 37  auto_year                    1000 non-null   int64  \n",
            " 38  fraud_reported               1000 non-null   object \n",
            " 39  _c39                         0 non-null      float64\n",
            "dtypes: float64(2), int64(17), object(21)\n",
            "memory usage: 312.6+ KB\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(   months_as_customer  age  policy_number policy_bind_date policy_state  \\\n",
              " 0                 328   48         521585       2014-10-17           OH   \n",
              " 1                 228   42         342868       2006-06-27           IN   \n",
              " 2                 134   29         687698       2000-09-06           OH   \n",
              " 3                 256   41         227811       1990-05-25           IL   \n",
              " 4                 228   44         367455       2014-06-06           IL   \n",
              " \n",
              "   policy_csl  policy_deductable  policy_annual_premium  umbrella_limit  \\\n",
              " 0    250/500               1000                1406.91               0   \n",
              " 1    250/500               2000                1197.22         5000000   \n",
              " 2    100/300               2000                1413.14         5000000   \n",
              " 3    250/500               2000                1415.74         6000000   \n",
              " 4   500/1000               1000                1583.91         6000000   \n",
              " \n",
              "    insured_zip  ... police_report_available total_claim_amount injury_claim  \\\n",
              " 0       466132  ...                     YES              71610         6510   \n",
              " 1       468176  ...                       ?               5070          780   \n",
              " 2       430632  ...                      NO              34650         7700   \n",
              " 3       608117  ...                      NO              63400         6340   \n",
              " 4       610706  ...                      NO               6500         1300   \n",
              " \n",
              "   property_claim vehicle_claim  auto_make  auto_model auto_year  \\\n",
              " 0          13020         52080       Saab         92x      2004   \n",
              " 1            780          3510   Mercedes        E400      2007   \n",
              " 2           3850         23100      Dodge         RAM      2007   \n",
              " 3           6340         50720  Chevrolet       Tahoe      2014   \n",
              " 4            650          4550     Accura         RSX      2009   \n",
              " \n",
              "   fraud_reported _c39  \n",
              " 0              Y  NaN  \n",
              " 1              Y  NaN  \n",
              " 2              N  NaN  \n",
              " 3              Y  NaN  \n",
              " 4              N  NaN  \n",
              " \n",
              " [5 rows x 40 columns],\n",
              " None)"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8qMJAUwvdKQO",
        "outputId": "bfe56c1b-d5be-4bcb-ca7c-ffdba8ff5e03"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[ 1.85857283,  1.75538603, -0.02570714,  0.05309623, -1.19323469,\n",
              "          0.0726197 ,  1.13089578,  1.06725697, -0.99685601, -1.38197061,\n",
              "         -0.32465569, -1.45569458, -0.59440215, -0.75287383,  1.16757627,\n",
              "         -0.150969  , -0.01386884, -0.20647062,  1.040777  ,  0.81967346,\n",
              "         -1.44450445,  1.74638548, -1.09697474, -0.8217921 , -0.63910148,\n",
              "         -1.2022249 , -1.34903791, -0.68205679, -1.29132474, -1.31468494,\n",
              "         -1.34838163, -1.24582545, -0.13259411, -0.82117201, -0.50697916],\n",
              "        [ 0.72046041,  0.65715437, -0.02570714,  1.30241929,  1.2607184 ,\n",
              "          0.99747437, -0.46754348, -0.93698147, -1.51103061, -1.62651308,\n",
              "         -1.03867508,  1.53187767,  0.10769496, -1.56438872, -0.69984548,\n",
              "         -1.08000899,  1.37301501,  0.85235309, -1.55036906,  0.81967346,\n",
              "          0.01828487, -0.62110648, -0.51723582,  1.1406965 ,  1.56469673,\n",
              "          0.00604133, -0.44364334, -0.68205679,  0.46723608, -0.57091155,\n",
              "          0.84602033,  0.62772934, -1.60586202,  0.3480762 , -1.18182662],\n",
              "        [ 1.69742417,  1.8652092 , -0.02570714, -1.19622683, -1.19323469,\n",
              "          1.73806682,  1.13089578,  1.06725697,  1.0598424 , -0.15925828,\n",
              "          0.92487824,  0.33684877,  0.73284993, -2.24824959, -1.04998706,\n",
              "          0.77807099, -0.01386884, -1.26529434, -1.55036906, -1.027478  ,\n",
              "         -0.46931157, -1.25984332, -0.66217055, -0.8217921 , -0.63910148,\n",
              "          1.21430757,  1.3671458 , -0.68205679,  1.65764649,  1.71802486,\n",
              "          0.45146037,  1.68956771,  0.35849519, -0.64128767, -0.16955542],\n",
              "        [-1.817631  , -0.55090046,  1.18404051,  1.30241929, -1.19323469,\n",
              "          0.1576638 , -0.46754348, -0.93698147, -0.99685601, -0.89288568,\n",
              "         -1.57418963, -0.26066568, -0.77713975,  0.82456524,  0.75907776,\n",
              "         -1.08000899,  1.37301501, -1.26529434,  1.040777  ,  1.28146133,\n",
              "          0.50588131,  0.44114064, -1.67671367,  2.1219408 , -0.63910148,\n",
              "         -1.2022249 , -1.34903791, -0.68205679,  0.60701912, -0.30901951,\n",
              "          1.09464715,  0.67492216, -0.86922807,  1.15755572, -1.51925035],\n",
              "        [ 0.55931175,  0.5473312 ,  1.18404051, -1.19622683,  0.03374186,\n",
              "          0.13285927, -0.46754348,  1.06725697,  0.5456678 ,  0.08528419,\n",
              "         -1.57418963, -0.26066568,  1.41571151,  0.37777614,  0.40893618,\n",
              "          0.77807099, -0.01386884,  0.85235309,  0.17706165,  1.28146133,\n",
              "          0.99347775, -0.05526896,  1.36691568, -0.8217921 , -0.63910148,\n",
              "         -1.2022249 , -0.44364334, -0.68205679, -0.63299171, -1.49800936,\n",
              "         -0.61871596,  0.01422273, -1.60586202,  1.24749789, -0.50697916]]),\n",
              " 887    0\n",
              " 317    0\n",
              " 796    1\n",
              " 425    1\n",
              " 991    0\n",
              " Name: fraud_reported, dtype: int64)"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "import numpy as np\n",
        "\n",
        "# Dropping columns that are not useful for prediction\n",
        "columns_to_drop = ['policy_number', 'policy_bind_date', 'insured_zip', '_c39']\n",
        "data = data.drop(columns=columns_to_drop)\n",
        "\n",
        "# Handling missing values (replace '?' with NaN and then use SimpleImputer)\n",
        "data = data.replace('?', np.nan)\n",
        "imputer = SimpleImputer(strategy='most_frequent')\n",
        "data_imputed = pd.DataFrame(imputer.fit_transform(data), columns=data.columns)\n",
        "\n",
        "# Encoding categorical variables\n",
        "label_encoders = {}\n",
        "for column in data_imputed.select_dtypes(include='object').columns:\n",
        "    if column != 'fraud_reported':\n",
        "        le = LabelEncoder()\n",
        "        data_imputed[column] = le.fit_transform(data_imputed[column])\n",
        "        label_encoders[column] = le\n",
        "\n",
        "# Encoding the target variable\n",
        "target_le = LabelEncoder()\n",
        "data_imputed['fraud_reported'] = target_le.fit_transform(data_imputed['fraud_reported'])\n",
        "\n",
        "# Splitting the data into features and target variable\n",
        "X = data_imputed.drop('fraud_reported', axis=1)\n",
        "y = data_imputed['fraud_reported']\n",
        "\n",
        "# Splitting the data into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# Standardizing the features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "X_train_scaled[:5], y_train[:5]\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "# Load the dataset\n",
        "file_path = '/content/carclaims.csv'\n",
        "data = pd.read_csv(file_path)\n",
        "\n",
        "# Dropping columns that are not useful for prediction\n",
        "columns_to_drop = ['policy_number', 'policy_bind_date', 'insured_zip', '_c39']\n",
        "data = data.drop(columns=columns_to_drop)\n",
        "\n",
        "# Handling missing values (replace '?' with NaN and then use SimpleImputer)\n",
        "data = data.replace('?', np.nan)\n",
        "imputer = SimpleImputer(strategy='most_frequent')\n",
        "data_imputed = pd.DataFrame(imputer.fit_transform(data), columns=data.columns)\n",
        "\n",
        "# Encoding categorical variables\n",
        "label_encoders = {}\n",
        "for column in data_imputed.select_dtypes(include='object').columns:\n",
        "    if column != 'fraud_reported':\n",
        "        le = LabelEncoder()\n",
        "        data_imputed[column] = le.fit_transform(data_imputed[column])\n",
        "        label_encoders[column] = le\n",
        "\n",
        "# Encoding the target variable\n",
        "target_le = LabelEncoder()\n",
        "data_imputed['fraud_reported'] = target_le.fit_transform(data_imputed['fraud_reported'])\n",
        "\n",
        "# Splitting the data into features and target variable\n",
        "X = data_imputed.drop('fraud_reported', axis=1)\n",
        "y = data_imputed['fraud_reported']\n",
        "\n",
        "# Splitting the data into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# Standardizing the features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Initialize the MLPClassifier\n",
        "mlp = MLPClassifier(hidden_layer_sizes=(64, 32), max_iter=100, alpha=0.0001,\n",
        "                    solver='adam', random_state=42, verbose=2)\n",
        "\n",
        "# Train the model\n",
        "mlp.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Predict on the test data\n",
        "y_pred = mlp.predict(X_test_scaled)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "report = classification_report(y_test, y_pred)\n",
        "\n",
        "print(f'Accuracy: {accuracy}')\n",
        "print('Classification Report:')\n",
        "print(report)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 368
        },
        "id": "NI3gIE_edsQC",
        "outputId": "05aaabef-bc0f-4d9f-ce4b-5bd3c30de70a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "\"['policy_number', 'policy_bind_date', 'insured_zip', '_c39'] not found in axis\"",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-0658e2cd1fbf>\u001b[0m in \u001b[0;36m<cell line: 15>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# Dropping columns that are not useful for prediction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mcolumns_to_drop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'policy_number'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'policy_bind_date'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'insured_zip'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_c39'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolumns_to_drop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# Handling missing values (replace '?' with NaN and then use SimpleImputer)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   5342\u001b[0m                 \u001b[0mweight\u001b[0m  \u001b[0;36m1.0\u001b[0m     \u001b[0;36m0.8\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5343\u001b[0m         \"\"\"\n\u001b[0;32m-> 5344\u001b[0;31m         return super().drop(\n\u001b[0m\u001b[1;32m   5345\u001b[0m             \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5346\u001b[0m             \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   4709\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4710\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4711\u001b[0;31m                 \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_drop_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4712\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4713\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_drop_axis\u001b[0;34m(self, labels, axis, level, errors, only_slice)\u001b[0m\n\u001b[1;32m   4751\u001b[0m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4752\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4753\u001b[0;31m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4754\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_axis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4755\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, errors)\u001b[0m\n\u001b[1;32m   6998\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6999\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 7000\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{labels[mask].tolist()} not found in axis\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   7001\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7002\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: \"['policy_number', 'policy_bind_date', 'insured_zip', '_c39'] not found in axis\""
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "# Load the dataset\n",
        "file_path = 'carclaims.csv'\n",
        "data = pd.read_csv(file_path)\n",
        "\n",
        "# Dropping columns that are not useful for prediction (adjust based on your dataset)\n",
        "# Example: columns_to_drop = ['unnecessary_column1', 'unnecessary_column2']\n",
        "columns_to_drop = []  # Add columns you want to drop here\n",
        "data = data.drop(columns=columns_to_drop)\n",
        "\n",
        "# Handling missing values (replace '?' with NaN and then use SimpleImputer)\n",
        "data = data.replace('?', np.nan)\n",
        "imputer = SimpleImputer(strategy='most_frequent')\n",
        "data_imputed = pd.DataFrame(imputer.fit_transform(data), columns=data.columns)\n",
        "\n",
        "# Encoding categorical variables\n",
        "label_encoders = {}\n",
        "for column in data_imputed.select_dtypes(include='object').columns:\n",
        "    if column != 'fraud':\n",
        "        le = LabelEncoder()\n",
        "        data_imputed[column] = le.fit_transform(data_imputed[column])\n",
        "        label_encoders[column] = le\n",
        "\n",
        "# Encoding the target variable\n",
        "target_le = LabelEncoder()\n",
        "data_imputed['FraudFound'] = target_le.fit_transform(data_imputed['FraudFound'])\n",
        "\n",
        "# Splitting the data into features and target variable\n",
        "X = data_imputed.drop('FraudFound', axis=1)\n",
        "y = data_imputed['FraudFound']\n",
        "\n",
        "# Splitting the data into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# Standardizing the features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Initialize the MLPClassifier\n",
        "mlp = MLPClassifier(hidden_layer_sizes=(64, 32), max_iter=100, alpha=0.001,\n",
        "                    solver='adam', random_state=42, verbose=2)\n",
        "\n",
        "# Train the model\n",
        "mlp.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Predict on the test data\n",
        "y_pred = mlp.predict(X_test_scaled)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "report = classification_report(y_test, y_pred)\n",
        "\n",
        "print(f'Accuracy: {accuracy}')\n",
        "print('Classification Report:')\n",
        "print(report)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ycUo9HjneVpg",
        "outputId": "c4c3b602-ecf2-47c6-e9b2-30e042d16ab1"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 1, loss = 0.27229571\n",
            "Iteration 2, loss = 0.20739137\n",
            "Iteration 3, loss = 0.19472989\n",
            "Iteration 4, loss = 0.18833342\n",
            "Iteration 5, loss = 0.18405706\n",
            "Iteration 6, loss = 0.18108817\n",
            "Iteration 7, loss = 0.17868346\n",
            "Iteration 8, loss = 0.17609770\n",
            "Iteration 9, loss = 0.17405816\n",
            "Iteration 10, loss = 0.17197794\n",
            "Iteration 11, loss = 0.16991555\n",
            "Iteration 12, loss = 0.16862541\n",
            "Iteration 13, loss = 0.16664168\n",
            "Iteration 14, loss = 0.16541518\n",
            "Iteration 15, loss = 0.16382914\n",
            "Iteration 16, loss = 0.16187438\n",
            "Iteration 17, loss = 0.16009328\n",
            "Iteration 18, loss = 0.15828186\n",
            "Iteration 19, loss = 0.15683316\n",
            "Iteration 20, loss = 0.15533487\n",
            "Iteration 21, loss = 0.15395982\n",
            "Iteration 22, loss = 0.15258494\n",
            "Iteration 23, loss = 0.15086820\n",
            "Iteration 24, loss = 0.14912333\n",
            "Iteration 25, loss = 0.14768875\n",
            "Iteration 26, loss = 0.14600635\n",
            "Iteration 27, loss = 0.14436765\n",
            "Iteration 28, loss = 0.14262788\n",
            "Iteration 29, loss = 0.14052472\n",
            "Iteration 30, loss = 0.13960685\n",
            "Iteration 31, loss = 0.13781639\n",
            "Iteration 32, loss = 0.13641341\n",
            "Iteration 33, loss = 0.13497207\n",
            "Iteration 34, loss = 0.13286919\n",
            "Iteration 35, loss = 0.13212048\n",
            "Iteration 36, loss = 0.13040470\n",
            "Iteration 37, loss = 0.12888075\n",
            "Iteration 38, loss = 0.12770810\n",
            "Iteration 39, loss = 0.12510928\n",
            "Iteration 40, loss = 0.12389332\n",
            "Iteration 41, loss = 0.12290096\n",
            "Iteration 42, loss = 0.12109444\n",
            "Iteration 43, loss = 0.11959747\n",
            "Iteration 44, loss = 0.11961673\n",
            "Iteration 45, loss = 0.11778879\n",
            "Iteration 46, loss = 0.11475287\n",
            "Iteration 47, loss = 0.11409660\n",
            "Iteration 48, loss = 0.11191691\n",
            "Iteration 49, loss = 0.11119502\n",
            "Iteration 50, loss = 0.10892478\n",
            "Iteration 51, loss = 0.10896464\n",
            "Iteration 52, loss = 0.10679559\n",
            "Iteration 53, loss = 0.10523329\n",
            "Iteration 54, loss = 0.10520157\n",
            "Iteration 55, loss = 0.10323963\n",
            "Iteration 56, loss = 0.10212166\n",
            "Iteration 57, loss = 0.09985562\n",
            "Iteration 58, loss = 0.09974750\n",
            "Iteration 59, loss = 0.09839418\n",
            "Iteration 60, loss = 0.09613753\n",
            "Iteration 61, loss = 0.09456243\n",
            "Iteration 62, loss = 0.09355570\n",
            "Iteration 63, loss = 0.09297868\n",
            "Iteration 64, loss = 0.09218346\n",
            "Iteration 65, loss = 0.09019755\n",
            "Iteration 66, loss = 0.08917839\n",
            "Iteration 67, loss = 0.08819771\n",
            "Iteration 68, loss = 0.08713015\n",
            "Iteration 69, loss = 0.08613007\n",
            "Iteration 70, loss = 0.08570538\n",
            "Iteration 71, loss = 0.08330903\n",
            "Iteration 72, loss = 0.08321691\n",
            "Iteration 73, loss = 0.08169912\n",
            "Iteration 74, loss = 0.08111858\n",
            "Iteration 75, loss = 0.07938414\n",
            "Iteration 76, loss = 0.07893111\n",
            "Iteration 77, loss = 0.07747506\n",
            "Iteration 78, loss = 0.07634670\n",
            "Iteration 79, loss = 0.07498150\n",
            "Iteration 80, loss = 0.07500235\n",
            "Iteration 81, loss = 0.07410279\n",
            "Iteration 82, loss = 0.07259276\n",
            "Iteration 83, loss = 0.07197087\n",
            "Iteration 84, loss = 0.07098010\n",
            "Iteration 85, loss = 0.06954133\n",
            "Iteration 86, loss = 0.07006627\n",
            "Iteration 87, loss = 0.06890256\n",
            "Iteration 88, loss = 0.06756126\n",
            "Iteration 89, loss = 0.06643762\n",
            "Iteration 90, loss = 0.06602222\n",
            "Iteration 91, loss = 0.06493933\n",
            "Iteration 92, loss = 0.06492461\n",
            "Iteration 93, loss = 0.06305925\n",
            "Iteration 94, loss = 0.06362426\n",
            "Iteration 95, loss = 0.06193130\n",
            "Iteration 96, loss = 0.06149967\n",
            "Iteration 97, loss = 0.06050097\n",
            "Iteration 98, loss = 0.05947111\n",
            "Iteration 99, loss = 0.05888296\n",
            "Iteration 100, loss = 0.05870939\n",
            "Accuracy: 0.9114785992217899\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.96      0.95      2899\n",
            "           1       0.21      0.18      0.19       185\n",
            "\n",
            "    accuracy                           0.91      3084\n",
            "   macro avg       0.58      0.57      0.57      3084\n",
            "weighted avg       0.90      0.91      0.91      3084\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "# Load the dataset\n",
        "file_path = 'carclaims.csv'\n",
        "data = pd.read_csv(file_path)\n",
        "\n",
        "# Dropping columns that are not useful for prediction (adjust based on your dataset)\n",
        "# Example: columns_to_drop = ['unnecessary_column1', 'unnecessary_column2']\n",
        "columns_to_drop = []  # Add columns you want to drop here\n",
        "data = data.drop(columns=columns_to_drop)\n",
        "\n",
        "# Handling missing values (replace '?' with NaN and then use SimpleImputer)\n",
        "data = data.replace('?', np.nan)\n",
        "imputer = SimpleImputer(strategy='most_frequent')\n",
        "data_imputed = pd.DataFrame(imputer.fit_transform(data), columns=data.columns)\n",
        "\n",
        "# Encoding categorical variables\n",
        "label_encoders = {}\n",
        "for column in data_imputed.select_dtypes(include='object').columns:\n",
        "    if column != 'FraudFound':\n",
        "        le = LabelEncoder()\n",
        "        data_imputed[column] = le.fit_transform(data_imputed[column])\n",
        "        label_encoders[column] = le\n",
        "\n",
        "# Encoding the target variable\n",
        "target_le = LabelEncoder()\n",
        "data_imputed['FraudFound'] = target_le.fit_transform(data_imputed['FraudFound'])\n",
        "\n",
        "# Splitting the data into features and target variable\n",
        "X = data_imputed.drop('FraudFound', axis=1)\n",
        "y = data_imputed['FraudFound']\n",
        "\n",
        "# Splitting the data into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# Standardizing the features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Initialize the MLPClassifier\n",
        "mlp = MLPClassifier(hidden_layer_sizes=(64, 32), max_iter=100, alpha=0.001,\n",
        "                    solver='adam', random_state=42, verbose=2)\n",
        "\n",
        "# Train the model\n",
        "mlp.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Predict on the test data\n",
        "y_pred = mlp.predict(X_test_scaled)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "report = classification_report(y_test, y_pred)\n",
        "\n",
        "print(f'Accuracy: {accuracy}')\n",
        "print('Classification Report:')\n",
        "print(report)\n",
        "\n",
        "# Example prediction\n",
        "# Use the first example from the test set\n",
        "example = X_test.iloc[0]\n",
        "example_scaled = scaler.transform([example])\n",
        "example_prediction = mlp.predict(example_scaled)\n",
        "\n",
        "print(f'Example input:\\n{example}')\n",
        "print(f'Predicted fraud (1 for fraud, 0 for no fraud): {example_prediction[0]}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Yli0OnAfxmI",
        "outputId": "d71e497f-5203-480d-8d30-7c969d417756"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 1, loss = 0.27229571\n",
            "Iteration 2, loss = 0.20739137\n",
            "Iteration 3, loss = 0.19472989\n",
            "Iteration 4, loss = 0.18833342\n",
            "Iteration 5, loss = 0.18405706\n",
            "Iteration 6, loss = 0.18108817\n",
            "Iteration 7, loss = 0.17868346\n",
            "Iteration 8, loss = 0.17609770\n",
            "Iteration 9, loss = 0.17405816\n",
            "Iteration 10, loss = 0.17197794\n",
            "Iteration 11, loss = 0.16991555\n",
            "Iteration 12, loss = 0.16862541\n",
            "Iteration 13, loss = 0.16664168\n",
            "Iteration 14, loss = 0.16541518\n",
            "Iteration 15, loss = 0.16382914\n",
            "Iteration 16, loss = 0.16187438\n",
            "Iteration 17, loss = 0.16009328\n",
            "Iteration 18, loss = 0.15828186\n",
            "Iteration 19, loss = 0.15683316\n",
            "Iteration 20, loss = 0.15533487\n",
            "Iteration 21, loss = 0.15395982\n",
            "Iteration 22, loss = 0.15258494\n",
            "Iteration 23, loss = 0.15086820\n",
            "Iteration 24, loss = 0.14912333\n",
            "Iteration 25, loss = 0.14768875\n",
            "Iteration 26, loss = 0.14600635\n",
            "Iteration 27, loss = 0.14436765\n",
            "Iteration 28, loss = 0.14262788\n",
            "Iteration 29, loss = 0.14052472\n",
            "Iteration 30, loss = 0.13960685\n",
            "Iteration 31, loss = 0.13781639\n",
            "Iteration 32, loss = 0.13641341\n",
            "Iteration 33, loss = 0.13497207\n",
            "Iteration 34, loss = 0.13286919\n",
            "Iteration 35, loss = 0.13212048\n",
            "Iteration 36, loss = 0.13040470\n",
            "Iteration 37, loss = 0.12888075\n",
            "Iteration 38, loss = 0.12770810\n",
            "Iteration 39, loss = 0.12510928\n",
            "Iteration 40, loss = 0.12389332\n",
            "Iteration 41, loss = 0.12290096\n",
            "Iteration 42, loss = 0.12109444\n",
            "Iteration 43, loss = 0.11959747\n",
            "Iteration 44, loss = 0.11961673\n",
            "Iteration 45, loss = 0.11778879\n",
            "Iteration 46, loss = 0.11475287\n",
            "Iteration 47, loss = 0.11409660\n",
            "Iteration 48, loss = 0.11191691\n",
            "Iteration 49, loss = 0.11119502\n",
            "Iteration 50, loss = 0.10892478\n",
            "Iteration 51, loss = 0.10896464\n",
            "Iteration 52, loss = 0.10679559\n",
            "Iteration 53, loss = 0.10523329\n",
            "Iteration 54, loss = 0.10520157\n",
            "Iteration 55, loss = 0.10323963\n",
            "Iteration 56, loss = 0.10212166\n",
            "Iteration 57, loss = 0.09985562\n",
            "Iteration 58, loss = 0.09974750\n",
            "Iteration 59, loss = 0.09839418\n",
            "Iteration 60, loss = 0.09613753\n",
            "Iteration 61, loss = 0.09456243\n",
            "Iteration 62, loss = 0.09355570\n",
            "Iteration 63, loss = 0.09297868\n",
            "Iteration 64, loss = 0.09218346\n",
            "Iteration 65, loss = 0.09019755\n",
            "Iteration 66, loss = 0.08917839\n",
            "Iteration 67, loss = 0.08819771\n",
            "Iteration 68, loss = 0.08713015\n",
            "Iteration 69, loss = 0.08613007\n",
            "Iteration 70, loss = 0.08570538\n",
            "Iteration 71, loss = 0.08330903\n",
            "Iteration 72, loss = 0.08321691\n",
            "Iteration 73, loss = 0.08169912\n",
            "Iteration 74, loss = 0.08111858\n",
            "Iteration 75, loss = 0.07938414\n",
            "Iteration 76, loss = 0.07893111\n",
            "Iteration 77, loss = 0.07747506\n",
            "Iteration 78, loss = 0.07634670\n",
            "Iteration 79, loss = 0.07498150\n",
            "Iteration 80, loss = 0.07500235\n",
            "Iteration 81, loss = 0.07410279\n",
            "Iteration 82, loss = 0.07259276\n",
            "Iteration 83, loss = 0.07197087\n",
            "Iteration 84, loss = 0.07098010\n",
            "Iteration 85, loss = 0.06954133\n",
            "Iteration 86, loss = 0.07006627\n",
            "Iteration 87, loss = 0.06890256\n",
            "Iteration 88, loss = 0.06756126\n",
            "Iteration 89, loss = 0.06643762\n",
            "Iteration 90, loss = 0.06602222\n",
            "Iteration 91, loss = 0.06493933\n",
            "Iteration 92, loss = 0.06492461\n",
            "Iteration 93, loss = 0.06305925\n",
            "Iteration 94, loss = 0.06362426\n",
            "Iteration 95, loss = 0.06193130\n",
            "Iteration 96, loss = 0.06149967\n",
            "Iteration 97, loss = 0.06050097\n",
            "Iteration 98, loss = 0.05947111\n",
            "Iteration 99, loss = 0.05888296\n",
            "Iteration 100, loss = 0.05870939\n",
            "Accuracy: 0.9114785992217899\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.96      0.95      2899\n",
            "           1       0.21      0.18      0.19       185\n",
            "\n",
            "    accuracy                           0.91      3084\n",
            "   macro avg       0.58      0.57      0.57      3084\n",
            "weighted avg       0.90      0.91      0.91      3084\n",
            "\n",
            "Example input:\n",
            "Month                      5\n",
            "WeekOfMonth                0\n",
            "DayOfWeek                  4\n",
            "Make                       2\n",
            "AccidentArea               1\n",
            "DayOfWeekClaimed           1\n",
            "MonthClaimed               6\n",
            "WeekOfMonthClaimed         2\n",
            "Sex                        1\n",
            "MaritalStatus              1\n",
            "Age                       26\n",
            "Fault                      0\n",
            "PolicyType                 2\n",
            "VehicleCategory            1\n",
            "VehiclePrice               0\n",
            "PolicyNumber            8922\n",
            "RepNumber                 15\n",
            "Deductible                 1\n",
            "DriverRating               3\n",
            "Days:Policy-Accident       3\n",
            "Days:Policy-Claim          2\n",
            "PastNumberOfClaims         3\n",
            "AgeOfVehicle               5\n",
            "AgeOfPolicyHolder          5\n",
            "PoliceReportFiled          0\n",
            "WitnessPresent             0\n",
            "AgentType                  0\n",
            "NumberOfSuppliments        3\n",
            "AddressChange-Claim        3\n",
            "NumberOfCars               0\n",
            "Year                       1\n",
            "BasePolicy                 2\n",
            "Name: 8922, dtype: int64\n",
            "Predicted fraud (1 for fraud, 0 for no fraud): 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Conv1D, Flatten, MaxPooling1D\n",
        "\n",
        "# Load the dataset\n",
        "file_path = 'carclaims.csv'\n",
        "data = pd.read_csv(file_path)\n",
        "\n",
        "# Dropping columns that are not useful for prediction (adjust based on your dataset)\n",
        "# Example: columns_to_drop = ['unnecessary_column1', 'unnecessary_column2']\n",
        "columns_to_drop = []  # Add columns you want to drop here\n",
        "data = data.drop(columns=columns_to_drop)\n",
        "\n",
        "# Handling missing values (replace '?' with NaN and then use SimpleImputer)\n",
        "data = data.replace('?', np.nan)\n",
        "imputer = SimpleImputer(strategy='most_frequent')\n",
        "data_imputed = pd.DataFrame(imputer.fit_transform(data), columns=data.columns)\n",
        "\n",
        "# Encoding categorical variables\n",
        "label_encoders = {}\n",
        "for column in data_imputed.select_dtypes(include='object').columns:\n",
        "    if column != 'FraudFound':\n",
        "        le = LabelEncoder()\n",
        "        data_imputed[column] = le.fit_transform(data_imputed[column])\n",
        "        label_encoders[column] = le\n",
        "\n",
        "# Encoding the target variable\n",
        "target_le = LabelEncoder()\n",
        "data_imputed['FraudFound'] = target_le.fit_transform(data_imputed['FraudFound'])\n",
        "\n",
        "# Splitting the data into features and target variable\n",
        "X = data_imputed.drop('FraudFound', axis=1)\n",
        "y = data_imputed['FraudFound']\n",
        "\n",
        "# Splitting the data into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# Standardizing the features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Reshape the data for CNN (1D Convolution)\n",
        "X_train_cnn = X_train_scaled.reshape(X_train_scaled.shape[0], X_train_scaled.shape[1], 1)\n",
        "X_test_cnn = X_test_scaled.reshape(X_test_scaled.shape[0], X_test_scaled.shape[1], 1)\n",
        "\n",
        "# Build the CNN model\n",
        "model = Sequential([\n",
        "    Conv1D(32, 3, activation='relu', input_shape=(X_train_cnn.shape[1], 1)),\n",
        "    MaxPooling1D(2),\n",
        "    Flatten(),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train_cnn, y_train, epochs=50, batch_size=32, validation_split=0.2, verbose=2)\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss, test_accuracy = model.evaluate(X_test_cnn, y_test, verbose=0)\n",
        "\n",
        "print(f'Test Accuracy: {test_accuracy}')\n",
        "\n",
        "# Predict on the test data\n",
        "y_pred = (model.predict(X_test_cnn) > 0.5).astype(\"int32\")\n",
        "\n",
        "# Evaluate the predictions\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "report = classification_report(y_test, y_pred)\n",
        "\n",
        "print(f'Accuracy: {accuracy}')\n",
        "print('Classification Report:')\n",
        "print(report)\n",
        "\n",
        "# Example prediction\n",
        "# Use the first example from the test set\n",
        "example = X_test.iloc[0]\n",
        "example_scaled = scaler.transform([example])\n",
        "example_cnn = example_scaled.reshape(1, example_scaled.shape[1], 1)\n",
        "example_prediction = model.predict(example_cnn)\n",
        "\n",
        "print(f'Example input:\\n{example}')\n",
        "print(f'Predicted fraud (1 for fraud, 0 for no fraud): {int(example_prediction[0] > 0.5)}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SWNgoDbWgU5H",
        "outputId": "0044b9f2-3760-493f-a1d6-bcfa13617fe9"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "309/309 - 3s - loss: 0.2290 - accuracy: 0.9351 - val_loss: 0.1900 - val_accuracy: 0.9461 - 3s/epoch - 10ms/step\n",
            "Epoch 2/50\n",
            "309/309 - 2s - loss: 0.2042 - accuracy: 0.9388 - val_loss: 0.1863 - val_accuracy: 0.9453 - 2s/epoch - 5ms/step\n",
            "Epoch 3/50\n",
            "309/309 - 1s - loss: 0.1984 - accuracy: 0.9386 - val_loss: 0.1822 - val_accuracy: 0.9461 - 1s/epoch - 3ms/step\n",
            "Epoch 4/50\n",
            "309/309 - 1s - loss: 0.1933 - accuracy: 0.9391 - val_loss: 0.1762 - val_accuracy: 0.9461 - 925ms/epoch - 3ms/step\n",
            "Epoch 5/50\n",
            "309/309 - 1s - loss: 0.1892 - accuracy: 0.9387 - val_loss: 0.1792 - val_accuracy: 0.9461 - 942ms/epoch - 3ms/step\n",
            "Epoch 6/50\n",
            "309/309 - 1s - loss: 0.1872 - accuracy: 0.9387 - val_loss: 0.1834 - val_accuracy: 0.9437 - 893ms/epoch - 3ms/step\n",
            "Epoch 7/50\n",
            "309/309 - 1s - loss: 0.1832 - accuracy: 0.9392 - val_loss: 0.1839 - val_accuracy: 0.9453 - 995ms/epoch - 3ms/step\n",
            "Epoch 8/50\n",
            "309/309 - 1s - loss: 0.1808 - accuracy: 0.9395 - val_loss: 0.1769 - val_accuracy: 0.9461 - 948ms/epoch - 3ms/step\n",
            "Epoch 9/50\n",
            "309/309 - 1s - loss: 0.1774 - accuracy: 0.9406 - val_loss: 0.1785 - val_accuracy: 0.9453 - 891ms/epoch - 3ms/step\n",
            "Epoch 10/50\n",
            "309/309 - 1s - loss: 0.1750 - accuracy: 0.9402 - val_loss: 0.1822 - val_accuracy: 0.9453 - 920ms/epoch - 3ms/step\n",
            "Epoch 11/50\n",
            "309/309 - 1s - loss: 0.1747 - accuracy: 0.9405 - val_loss: 0.1789 - val_accuracy: 0.9461 - 979ms/epoch - 3ms/step\n",
            "Epoch 12/50\n",
            "309/309 - 1s - loss: 0.1704 - accuracy: 0.9407 - val_loss: 0.1818 - val_accuracy: 0.9441 - 935ms/epoch - 3ms/step\n",
            "Epoch 13/50\n",
            "309/309 - 1s - loss: 0.1684 - accuracy: 0.9407 - val_loss: 0.1925 - val_accuracy: 0.9457 - 1s/epoch - 4ms/step\n",
            "Epoch 14/50\n",
            "309/309 - 2s - loss: 0.1658 - accuracy: 0.9410 - val_loss: 0.1825 - val_accuracy: 0.9445 - 2s/epoch - 5ms/step\n",
            "Epoch 15/50\n",
            "309/309 - 1s - loss: 0.1614 - accuracy: 0.9421 - val_loss: 0.1865 - val_accuracy: 0.9437 - 1s/epoch - 5ms/step\n",
            "Epoch 16/50\n",
            "309/309 - 1s - loss: 0.1590 - accuracy: 0.9434 - val_loss: 0.1834 - val_accuracy: 0.9433 - 916ms/epoch - 3ms/step\n",
            "Epoch 17/50\n",
            "309/309 - 1s - loss: 0.1573 - accuracy: 0.9438 - val_loss: 0.1901 - val_accuracy: 0.9425 - 913ms/epoch - 3ms/step\n",
            "Epoch 18/50\n",
            "309/309 - 1s - loss: 0.1565 - accuracy: 0.9424 - val_loss: 0.1904 - val_accuracy: 0.9437 - 880ms/epoch - 3ms/step\n",
            "Epoch 19/50\n",
            "309/309 - 1s - loss: 0.1514 - accuracy: 0.9443 - val_loss: 0.1886 - val_accuracy: 0.9425 - 1s/epoch - 3ms/step\n",
            "Epoch 20/50\n",
            "309/309 - 1s - loss: 0.1484 - accuracy: 0.9455 - val_loss: 0.1924 - val_accuracy: 0.9449 - 919ms/epoch - 3ms/step\n",
            "Epoch 21/50\n",
            "309/309 - 1s - loss: 0.1445 - accuracy: 0.9465 - val_loss: 0.1916 - val_accuracy: 0.9400 - 910ms/epoch - 3ms/step\n",
            "Epoch 22/50\n",
            "309/309 - 1s - loss: 0.1410 - accuracy: 0.9476 - val_loss: 0.2028 - val_accuracy: 0.9445 - 933ms/epoch - 3ms/step\n",
            "Epoch 23/50\n",
            "309/309 - 1s - loss: 0.1394 - accuracy: 0.9484 - val_loss: 0.1979 - val_accuracy: 0.9433 - 943ms/epoch - 3ms/step\n",
            "Epoch 24/50\n",
            "309/309 - 1s - loss: 0.1363 - accuracy: 0.9477 - val_loss: 0.2099 - val_accuracy: 0.9433 - 927ms/epoch - 3ms/step\n",
            "Epoch 25/50\n",
            "309/309 - 1s - loss: 0.1349 - accuracy: 0.9485 - val_loss: 0.2071 - val_accuracy: 0.9340 - 956ms/epoch - 3ms/step\n",
            "Epoch 26/50\n",
            "309/309 - 1s - loss: 0.1304 - accuracy: 0.9509 - val_loss: 0.2141 - val_accuracy: 0.9449 - 1s/epoch - 4ms/step\n",
            "Epoch 27/50\n",
            "309/309 - 2s - loss: 0.1287 - accuracy: 0.9499 - val_loss: 0.2172 - val_accuracy: 0.9344 - 2s/epoch - 5ms/step\n",
            "Epoch 28/50\n",
            "309/309 - 1s - loss: 0.1271 - accuracy: 0.9502 - val_loss: 0.2148 - val_accuracy: 0.9348 - 1s/epoch - 5ms/step\n",
            "Epoch 29/50\n",
            "309/309 - 1s - loss: 0.1233 - accuracy: 0.9543 - val_loss: 0.2205 - val_accuracy: 0.9299 - 902ms/epoch - 3ms/step\n",
            "Epoch 30/50\n",
            "309/309 - 1s - loss: 0.1227 - accuracy: 0.9530 - val_loss: 0.2176 - val_accuracy: 0.9408 - 934ms/epoch - 3ms/step\n",
            "Epoch 31/50\n",
            "309/309 - 1s - loss: 0.1185 - accuracy: 0.9546 - val_loss: 0.2272 - val_accuracy: 0.9344 - 875ms/epoch - 3ms/step\n",
            "Epoch 32/50\n",
            "309/309 - 1s - loss: 0.1152 - accuracy: 0.9555 - val_loss: 0.2313 - val_accuracy: 0.9380 - 918ms/epoch - 3ms/step\n",
            "Epoch 33/50\n",
            "309/309 - 1s - loss: 0.1133 - accuracy: 0.9569 - val_loss: 0.2267 - val_accuracy: 0.9360 - 927ms/epoch - 3ms/step\n",
            "Epoch 34/50\n",
            "309/309 - 1s - loss: 0.1126 - accuracy: 0.9557 - val_loss: 0.2360 - val_accuracy: 0.9226 - 931ms/epoch - 3ms/step\n",
            "Epoch 35/50\n",
            "309/309 - 1s - loss: 0.1096 - accuracy: 0.9597 - val_loss: 0.2422 - val_accuracy: 0.9238 - 891ms/epoch - 3ms/step\n",
            "Epoch 36/50\n",
            "309/309 - 1s - loss: 0.1082 - accuracy: 0.9593 - val_loss: 0.2365 - val_accuracy: 0.9259 - 929ms/epoch - 3ms/step\n",
            "Epoch 37/50\n",
            "309/309 - 1s - loss: 0.1083 - accuracy: 0.9594 - val_loss: 0.2402 - val_accuracy: 0.9348 - 901ms/epoch - 3ms/step\n",
            "Epoch 38/50\n",
            "309/309 - 1s - loss: 0.1048 - accuracy: 0.9605 - val_loss: 0.2399 - val_accuracy: 0.9238 - 889ms/epoch - 3ms/step\n",
            "Epoch 39/50\n",
            "309/309 - 1s - loss: 0.1005 - accuracy: 0.9612 - val_loss: 0.2528 - val_accuracy: 0.9234 - 928ms/epoch - 3ms/step\n",
            "Epoch 40/50\n",
            "309/309 - 2s - loss: 0.0975 - accuracy: 0.9629 - val_loss: 0.2562 - val_accuracy: 0.9368 - 2s/epoch - 5ms/step\n",
            "Epoch 41/50\n",
            "309/309 - 2s - loss: 0.0958 - accuracy: 0.9631 - val_loss: 0.2575 - val_accuracy: 0.9311 - 2s/epoch - 5ms/step\n",
            "Epoch 42/50\n",
            "309/309 - 1s - loss: 0.0940 - accuracy: 0.9639 - val_loss: 0.2634 - val_accuracy: 0.9368 - 931ms/epoch - 3ms/step\n",
            "Epoch 43/50\n",
            "309/309 - 1s - loss: 0.0937 - accuracy: 0.9638 - val_loss: 0.2643 - val_accuracy: 0.9210 - 928ms/epoch - 3ms/step\n",
            "Epoch 44/50\n",
            "309/309 - 1s - loss: 0.0891 - accuracy: 0.9661 - val_loss: 0.2595 - val_accuracy: 0.9242 - 888ms/epoch - 3ms/step\n",
            "Epoch 45/50\n",
            "309/309 - 1s - loss: 0.0900 - accuracy: 0.9663 - val_loss: 0.2822 - val_accuracy: 0.9250 - 919ms/epoch - 3ms/step\n",
            "Epoch 46/50\n",
            "309/309 - 1s - loss: 0.0878 - accuracy: 0.9670 - val_loss: 0.2731 - val_accuracy: 0.9279 - 881ms/epoch - 3ms/step\n",
            "Epoch 47/50\n",
            "309/309 - 1s - loss: 0.0850 - accuracy: 0.9666 - val_loss: 0.2863 - val_accuracy: 0.9210 - 926ms/epoch - 3ms/step\n",
            "Epoch 48/50\n",
            "309/309 - 1s - loss: 0.0867 - accuracy: 0.9668 - val_loss: 0.2819 - val_accuracy: 0.9226 - 919ms/epoch - 3ms/step\n",
            "Epoch 49/50\n",
            "309/309 - 1s - loss: 0.0800 - accuracy: 0.9686 - val_loss: 0.2914 - val_accuracy: 0.9173 - 998ms/epoch - 3ms/step\n",
            "Epoch 50/50\n",
            "309/309 - 1s - loss: 0.0774 - accuracy: 0.9709 - val_loss: 0.2909 - val_accuracy: 0.9303 - 905ms/epoch - 3ms/step\n",
            "Test Accuracy: 0.9244487881660461\n",
            "97/97 [==============================] - 0s 2ms/step\n",
            "Accuracy: 0.9244487678339819\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.98      0.96      2899\n",
            "           1       0.21      0.09      0.13       185\n",
            "\n",
            "    accuracy                           0.92      3084\n",
            "   macro avg       0.58      0.53      0.54      3084\n",
            "weighted avg       0.90      0.92      0.91      3084\n",
            "\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "Example input:\n",
            "Month                      5\n",
            "WeekOfMonth                0\n",
            "DayOfWeek                  4\n",
            "Make                       2\n",
            "AccidentArea               1\n",
            "DayOfWeekClaimed           1\n",
            "MonthClaimed               6\n",
            "WeekOfMonthClaimed         2\n",
            "Sex                        1\n",
            "MaritalStatus              1\n",
            "Age                       26\n",
            "Fault                      0\n",
            "PolicyType                 2\n",
            "VehicleCategory            1\n",
            "VehiclePrice               0\n",
            "PolicyNumber            8922\n",
            "RepNumber                 15\n",
            "Deductible                 1\n",
            "DriverRating               3\n",
            "Days:Policy-Accident       3\n",
            "Days:Policy-Claim          2\n",
            "PastNumberOfClaims         3\n",
            "AgeOfVehicle               5\n",
            "AgeOfPolicyHolder          5\n",
            "PoliceReportFiled          0\n",
            "WitnessPresent             0\n",
            "AgentType                  0\n",
            "NumberOfSuppliments        3\n",
            "AddressChange-Claim        3\n",
            "NumberOfCars               0\n",
            "Year                       1\n",
            "BasePolicy                 2\n",
            "Name: 8922, dtype: int64\n",
            "Predicted fraud (1 for fraud, 0 for no fraud): 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "<ipython-input-12-a4142318fd06>:92: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  print(f'Predicted fraud (1 for fraud, 0 for no fraud): {int(example_prediction[0] > 0.5)}')\n"
          ]
        }
      ]
    }
  ]
}